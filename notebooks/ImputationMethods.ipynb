{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde66d24-68cf-422a-949e-369d242a7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from statsmodels.tsa.arima.model import ARIMA \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d9c11-8396-4e2b-89e2-1e6ecbd78f86",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9f90ab-9224-49ba-91f1-ce6240e4401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"../data/raw/final_merged_data.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f902233e-cb0d-49a3-a162-1feeed5fb8b5",
   "metadata": {},
   "source": [
    "# Replace -1 with NaN for processing\n",
    "columns_with_nan = [\"inside_temperature\", \"inside_humidity\"]\n",
    "data[columns_with_nan] = data[columns_with_nan].replace(-1, np.nan)\n",
    "print(data[columns_with_nan].isna().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10cc7f8a-9f0d-4969-9913-5b87d89c8235",
   "metadata": {},
   "source": [
    "print(data[columns_with_nan].head(10))\n",
    "mask = data[columns_with_nan].isna()\n",
    "print(mask.sum())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cb85f03-5315-41ea-a330-59d26c6d188a",
   "metadata": {},
   "source": [
    "# Analyze and Visualize the Data\n",
    "print(\"Basic Dataset Information:\")\n",
    "print(data.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ad8e3a5-9d9f-4042-b727-45367461d1f6",
   "metadata": {},
   "source": [
    "# Count and visualize missing values\n",
    "missing_counts = data.isna().sum()\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(missing_counts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86294286-79c0-448c-b7a9-b80afb904a68",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "missing_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Missing Values per Column\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b54e687-9c1b-4ba4-b9bc-9c47163c36ff",
   "metadata": {},
   "source": [
    "# Visualize the data distribution\n",
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    data[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fa8c53c-d03e-4b17-abc8-216ae2487c31",
   "metadata": {},
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def analyze_missing_gaps(data, columns_with_nan):\n",
    "    gaps_info = []\n",
    "    for col in columns_with_nan:\n",
    "        data['gap'] = data[col].isna()\n",
    "        data['gap_id'] = (data['gap'] != data['gap'].shift()).cumsum()\n",
    "        \n",
    "        missing_gaps = data[data['gap']].groupby('gap_id')\n",
    "        \n",
    "        for gap_id, gap_data in missing_gaps:\n",
    "            start_time = gap_data['time'].iloc[0]\n",
    "            end_time = gap_data['time'].iloc[-1]\n",
    "            gap_count = len(gap_data)\n",
    "            \n",
    "            # Calculate duration of the gap\n",
    "            gap_duration = (pd.to_datetime(end_time) - pd.to_datetime(start_time)) + pd.Timedelta(minutes=1)\n",
    "            \n",
    "            # Format duration as '0 days HH:mm:ss'\n",
    "            gap_duration_str = str(gap_duration)\n",
    "            \n",
    "            gaps_info.append({\n",
    "                \"Column\": col,\n",
    "                \"Start Time\": start_time,\n",
    "                \"End Time\": end_time,\n",
    "                \"Duration\": gap_duration_str,\n",
    "            })\n",
    "    \n",
    "    gaps_df = pd.DataFrame(gaps_info)\n",
    "    \n",
    "    # Count the frequency of each unique duration for each column\n",
    "    frequency_summary = gaps_df.groupby(['Column', 'Duration']).size().reset_index(name='Count')\n",
    "    return frequency_summary\n",
    "\n",
    "\n",
    "# Generate gap analysis and display results\n",
    "gaps_summary = analyze_missing_gaps(data, columns_with_nan)\n",
    "\n",
    "print(\"Missing Gaps Summary:\")\n",
    "print(tabulate(gaps_summary, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "\n",
    "for col in columns_with_nan:\n",
    "    col_summary = gaps_summary[gaps_summary[\"Column\"] == col]\n",
    "    print(f\"Aggregated Missing Gaps Summary for {col}:\")\n",
    "    print(tabulate(col_summary, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Plot gaps frequency for each column\n",
    "for col in columns_with_nan:\n",
    "    col_gaps = gaps_summary[gaps_summary['Column'] == col]\n",
    "    \n",
    "    col_gaps['Duration Hours'] = pd.to_timedelta(col_gaps['Duration']).dt.total_seconds() / 3600\n",
    "\n",
    "    duration_counts = col_gaps['Duration Hours'].value_counts().reset_index()\n",
    "    duration_counts.columns = ['Duration (hours)', 'Frequency']\n",
    "    duration_counts.sort_values(by='Duration (hours)', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(col_gaps['Duration'], col_gaps['Count'], color='skyblue', edgecolor='black')\n",
    "    plt.xlabel(\"Gap Duration (hours)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Frequency of Gap Durations\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "721429b5-a5e8-42c6-be5d-d951a83dba6e",
   "metadata": {},
   "source": [
    "# Imputation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28c1b184-ddbd-42e5-83dc-fb95571e8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imputation(original, imputed, method):\n",
    "    mask = ~original.isna()\n",
    "    mse = np.mean((original[mask] - imputed[mask])**2)\n",
    "    print(f\"{method} MSE: {mse}\")\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c674f35a-b8d9-48bf-9573-7fc3398fd07e",
   "metadata": {},
   "source": [
    "original_data = data.dropna(subset=columns_with_nan).copy()\n",
    "mask = data[columns_with_nan].isna()\n",
    "print(original_data.isna().sum())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "80315708-edf5-49dc-a4e1-b43d07ae4f9c",
   "metadata": {},
   "source": [
    "## Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "id": "320d234a-56bb-4b22-8761-e549810ddff8",
   "metadata": {},
   "source": [
    "# Mean Imputation\n",
    "mean_imputed = data.copy()\n",
    "for col in columns_with_nan:\n",
    "    mean_imputed[col].fillna(mean_imputed[col].mean(), inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f95223fd-7e8e-4594-a9d8-e68c74f2f9fe",
   "metadata": {},
   "source": [
    "# Median Imputation\n",
    "median_imputed = data.copy()\n",
    "for col in columns_with_nan:\n",
    "    median_imputed[col].fillna(median_imputed[col].median(), inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63f07597-7b9a-49f0-9d80-8cfa35cdfc81",
   "metadata": {},
   "source": [
    "# LOCF (Last Observation Carried Forward)\n",
    "locf_imputed = data.copy()\n",
    "locf_imputed[columns_with_nan] = locf_imputed[columns_with_nan].fillna(method='ffill')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5174be35-0dd9-46f0-a720-16d9a4e50473",
   "metadata": {},
   "source": [
    "# NOCB (Next Observation Carried Backward)\n",
    "nocb_imputed = data.copy()\n",
    "nocb_imputed[columns_with_nan] = nocb_imputed[columns_with_nan].fillna(method='bfill')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45ba0cc4-aa83-4b69-b8ca-f0a25ce8279f",
   "metadata": {},
   "source": [
    "## Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6d05c7a-c424-4bdd-940a-86245d6a14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Interpolation\n",
    "linear_imputed = data.copy()\n",
    "linear_imputed[columns_with_nan] = linear_imputed[columns_with_nan].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad9c04-423f-4861-988e-343a90c82c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spline Interpolation\n",
    "spline_imputed = data.copy()\n",
    "spline_imputed[columns_with_nan] = spline_imputed[columns_with_nan].interpolate(method='spline', order=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d43817-e9cd-4d5f-b5b5-6acd2300d1cf",
   "metadata": {},
   "source": [
    "## Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7c4c159-54d8-4066-8ad1-859b7c50e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=60) # 60 neighbors to look up at the 1 hour interval\n",
    "knn_imputed = data.copy()\n",
    "knn_imputed[columns_with_nan] = knn_imputer.fit_transform(knn_imputed[columns_with_nan])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f5329-fcc3-4e42-b87b-6ffbad88a0fe",
   "metadata": {},
   "source": [
    "# ARIMA-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c73a899-e98e-44b7-9669-77d4a5fd2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_imputation(series):\n",
    "    series_imputed = series.copy()\n",
    "    for i in range(len(series)):\n",
    "        if pd.isna(series[i]):\n",
    "            model = ARIMA(series[:i].dropna(), order=(1, 1, 1))\n",
    "            model_fit = model.fit()\n",
    "            series_imputed[i] = model_fit.forecast()[0]\n",
    "    return series_imputed"
   ]
  },
  {
   "cell_type": "code",
   "id": "7930cb7e-1859-47d5-8f00-1b64389fa6be",
   "metadata": {},
   "source": [
    "arima_imputed = data.copy()\n",
    "arima_imputed[\"inside_temperature\"] = arima_imputation(data[\"inside_temperature\"])\n",
    "arima_imputed[\"inside_humidity\"] = arima_imputation(data[\"inside_humidity\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2317c107-e137-4bc1-aef7-ffc160df8eaa",
   "metadata": {},
   "source": [
    "# Compare Techniques"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d1edf81-3983-4484-a67d-346dfb57ea89",
   "metadata": {},
   "source": [
    "print(data[columns_with_nan].isna().sum())\n",
    "print(linear_imputed[columns_with_nan].isna().sum())\n",
    "print(mean_imputed[columns_with_nan].isna().sum())\n",
    "print(median_imputed[columns_with_nan].isna().sum())\n",
    "print(locf_imputed[columns_with_nan].isna().sum())\n",
    "print(nocb_imputed[columns_with_nan].isna().sum())\n",
    "print(knn_imputed[columns_with_nan].isna().sum())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0970ba93-67b1-43ad-994d-0ebc1874d898",
   "metadata": {},
   "source": [
    "print('Knn')\n",
    "print(knn_imputed.describe())\n",
    "print('linear_imputed')\n",
    "\n",
    "print(linear_imputed.describe())\n",
    "print('mean_imputed')\n",
    "\n",
    "print(mean_imputed.describe())\n",
    "print('median_imputed')\n",
    "\n",
    "print(median_imputed.describe())\n",
    "print('locf_imputed')\n",
    "\n",
    "print(locf_imputed.describe())\n",
    "print('nocb_imputed')\n",
    "\n",
    "print(nocb_imputed.describe())\n",
    "print('data')\n",
    "\n",
    "\n",
    "print(data.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec300f23-e750-4774-8629-b3a254b9cdcf",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    nocb_imputed[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fed0284-5a02-47b9-9a49-338f338a8868",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    locf_imputed[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e18d5e79-c322-430d-99f7-0c74dbffdcb9",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    median_imputed[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "95285979-aed9-4930-a333-5375c3d440c6",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    mean_imputed[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0480a5c9-410a-47e0-b356-fd2f5a699a3a",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    linear_imputed[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "### Custom imputation/interpolation algorithm",
   "id": "7ce887fd45a236f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 35,
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def impute_missing_gaps_independently(data, zone_column, time_column, value_column):\n",
    "    \"\"\"\n",
    "    Impute missing gaps independently for each zone and time.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data[time_column] = pd.to_datetime(data[time_column])\n",
    "    data = data.sort_values(by=[zone_column, time_column])\n",
    "\n",
    "    processed_zones = []\n",
    "\n",
    "    for zone, zone_data in data.groupby(zone_column):\n",
    "        zone_data = zone_data.copy()\n",
    "        zone_data['gap'] = zone_data[value_column].isna()\n",
    "        zone_data['gap_id'] = (zone_data['gap'] != zone_data['gap'].shift()).cumsum()\n",
    "\n",
    "        for gap_id, gap_data in zone_data.groupby('gap_id'):\n",
    "            if not gap_data['gap'].iloc[0]:\n",
    "                continue\n",
    "\n",
    "            gap_mask = (zone_data['gap_id'] == gap_id) & zone_data['gap']\n",
    "            start_time = gap_data[time_column].iloc[0]\n",
    "            end_time = gap_data[time_column].iloc[-1]\n",
    "            gap_duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "            if gap_duration <= 10:\n",
    "                temp_series = pd.Series(zone_data[value_column].values,\n",
    "                                      index=zone_data[time_column])\n",
    "                filled_values = temp_series.interpolate(method='linear')\n",
    "                zone_data.loc[gap_mask, value_column] = filled_values[gap_data[time_column]].values\n",
    "            elif 10 < gap_duration <= 60:\n",
    "                temp_series = pd.Series(zone_data[value_column].values,\n",
    "                                      index=zone_data[time_column])\n",
    "                filled_values = temp_series.interpolate(method='time')\n",
    "                zone_data.loc[gap_mask, value_column] = filled_values[gap_data[time_column]].values\n",
    "            elif gap_duration > 60:\n",
    "                # Create a time series with only non-null values\n",
    "                valid_data = zone_data[~zone_data[value_column].isna()]\n",
    "                if len(valid_data) < 1440:  # If not enough data for seasonal decomposition\n",
    "                    temp_series = pd.Series(zone_data[value_column].values,\n",
    "                                          index=zone_data[time_column])\n",
    "                    filled_values = temp_series.interpolate(method='time')\n",
    "                    zone_data.loc[gap_mask, value_column] = filled_values[gap_data[time_column]].values\n",
    "                else:\n",
    "                    temp_series = pd.Series(valid_data[value_column].values,\n",
    "                                          index=valid_data[time_column])\n",
    "                    try:\n",
    "                        decomposed = seasonal_decompose(temp_series, period=1440)\n",
    "                        trend = pd.Series(decomposed.trend, index=temp_series.index)\n",
    "                        trend = trend.ffill().bfill()\n",
    "                        # Reindex trend to match gap dates\n",
    "                        trend_reindexed = trend.reindex(gap_data[time_column])\n",
    "                        zone_data.loc[gap_mask, value_column] = trend_reindexed.values\n",
    "                    except:\n",
    "                        # Fallback to time-based interpolation if decomposition fails\n",
    "                        temp_series = pd.Series(zone_data[value_column].values,\n",
    "                                              index=zone_data[time_column])\n",
    "                        filled_values = temp_series.interpolate(method='time')\n",
    "                        zone_data.loc[gap_mask, value_column] = filled_values[gap_data[time_column]].values\n",
    "            else:\n",
    "                zone_data.loc[gap_mask, value_column] = zone_data[value_column].ffill()\n",
    "\n",
    "        zone_data = zone_data.drop(columns=['gap', 'gap_id'])\n",
    "        processed_zones.append(zone_data)\n",
    "\n",
    "    result = pd.concat(processed_zones)\n",
    "    return result\n",
    "\n",
    "cleaned_data = impute_missing_gaps_independently(data, 'zone', 'time', 'inside_temperature')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'inside_humidity')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'GHI')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'DNI')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'DHI')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'outside_temperature')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'outside_humidity')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'BP')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'WS')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'WD_Avg')\n",
    "cleaned_data = impute_missing_gaps_independently(cleaned_data, 'zone', 'time', 'WSgust_Max')"
   ],
   "id": "db047cc2-3f05-4607-9142-31f145394af3"
  },
  {
   "cell_type": "code",
   "id": "0deffb02-4900-47fb-84a0-d99423e043ae",
   "metadata": {},
   "source": [
    "print(cleaned_data.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7bbdf63-0013-4dcf-aba3-b566aaf73abf",
   "metadata": {},
   "source": [
    "cleaned_data.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "027cadd6-9ee7-43ae-aa3c-4392583dcb1e",
   "metadata": {},
   "outputs": [],
   "source": "cleaned_data.to_csv('../data/processed/imputedData.csv', index=False)"
  },
  {
   "cell_type": "code",
   "id": "f333424e-d1ab-4031-956b-b4f14fecec2f",
   "metadata": {},
   "source": [
    "cleaned_data['inside_temperature', 'inside_humidity'].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18fde828-5101-428f-9c66-5c42a6a896c5",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    cleaned_data[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9e1d469-cd9c-4318-ba77-ca9a7734be45",
   "metadata": {},
   "source": [
    "for col in columns_with_nan:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    data[col].plot(kind='hist', bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3937553-a151-430b-922b-95ec2719289c",
   "metadata": {},
   "source": [
    "columns = ['inside_temperature', 'inside_humidity','GHI','DNI','DHI','outside_temperature','outside humidity','BP','WS','WD_Avg','WSgust_Max']  \n",
    "\n",
    "for col in columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(data[col], bins=30, alpha=0.5, label='Original', color = 'blue')\n",
    "    plt.hist(cleaned_data[col], bins=30, alpha=0.5, label='Cleaned', color = 'green')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2207419-0241-477a-b571-5c64b05429be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
